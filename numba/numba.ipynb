{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9bf378-9d94-49ea-b4ed-7c041e189b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from numba import jit, njit, vectorize, guvectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc86f6-06ac-4ea3-b21e-682b984a19d9",
   "metadata": {},
   "source": [
    "# Numba\n",
    "\n",
    "**Numba** is a just-in-time (JIT) compiler that translates Python functions into optimized machine code at runtime. \n",
    "\n",
    "When a Python function is decorated with Numba, it gets compiled into highly efficient machine code the first time it's called, resulting in performance improvements ranging from 2x to 100x compared to pure Python code. This is particularly powerful for numerical computations and algorithms that would otherwise be slow in standard Python.\n",
    "\n",
    "Key benefits of Numba:\n",
    "- Near-C execution speeds while writing pure Python code\n",
    "- Automatic parallelization capabilities\n",
    "- Minimal code changes required - often just a decorator\n",
    "\n",
    "In this notebook, we'll explore some basic examples of using Numba to optimize Python functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef8964-3415-4dee-81f6-72d5778d420c",
   "metadata": {},
   "source": [
    "## @jit Decorator\n",
    "\n",
    "### The Basics\n",
    "\n",
    "The `@numba.jit` decorator enables just-in-time (JIT) compilation of Python functions, potentially yielding significant performance improvements over pure Python execution. \n",
    "\n",
    "Numba achieves its best performance improvements when working with:\n",
    "- **NumPy arrays**: Numba excels at optimizing operations on NumPy arrays\n",
    "- **Numerical computations**: Loops and mathematical operations get heavily optimized\n",
    "- **Type-stable code**: Functions where variable types don't change during execution\n",
    "\n",
    "When a decorated function is called, Numba performs _type inference_ - automatically determining the types of all variables in the function. Based on these inferred types, it generates optimized machine code specifically for those types.\n",
    "\n",
    "Let's start with a simple example to demonstrate Numba's capabilities: computing the sum of all elements in a NumPy array. This example will show the basic usage of the `@jit` decorator and its performance impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf216b8c-0e93-4f2c-8b8e-28a7186a1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum of all elements in an array using Numba\n",
    "@jit\n",
    "def simple_sum(data):\n",
    "    s = 0\n",
    "    for d in data:  # Explicit loop will be optimized by Numba\n",
    "        s += d\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9cc1f-b473-4737-bb5f-af86af4e5d9c",
   "metadata": {},
   "source": [
    "Adding the decorator to the function instructs Numba to compile it to machine-code the first time this function is called.\n",
    "\n",
    "Once compiled, Numba maintains:\n",
    "- The compiled \"jitted\" version for optimized execution\n",
    "- The original Python implementation, accessible via `simple_sum.py_func()`\n",
    "\n",
    "This allows you to:\n",
    "1. Compare performance between compiled and interpreted versions\n",
    "2. Access the original Python code for debugging\n",
    "3. Verify the correctness of the compilation by comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06397ef8-1840-4686-97f9-32ccde9e4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an arbitrary vector to test `simple_sum` function\n",
    "input_data = 10*np.random.random(100_000)\n",
    "input_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aafd6b-a79b-446f-afaf-ac148aa79613",
   "metadata": {},
   "source": [
    "`for` loops in Python are notoriously slow due to several factors:\n",
    "- Python's dynamic typing requires type checking at each iteration\n",
    "- The interpreter overhead on each loop iteration\n",
    "- The flexibility of Python objects adds runtime costs\n",
    "\n",
    "The conventional solution is to use NumPy's vectorized operations instead of explicit loops:\n",
    "- NumPy functions are implemented in `C`\n",
    "- They operate on entire arrays at once\n",
    "- Array operations bypass Python's interpreter overhead\n",
    "\n",
    "For our sum example, NumPy provides the built-in `np.sum()` function that efficiently computes array sums without explicit loops.\n",
    "However, this example is to be considered as a starting point for understanding how and where Numba can provide an advantage in speeding up purely Pythonic code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234eb38-1db1-4ae7-87dc-0346c46c7b98",
   "metadata": {},
   "source": [
    "Let's now compare the execution time across the tree alternatives:\n",
    "- The purely pythonic function implementation\n",
    "- The same pythonic function `jit`-compiled by Numba\n",
    "- The NumPy `np.sum` alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28691c-90a9-4a1f-894a-8c84e2bcc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 -r 5\n",
    "\n",
    "# Purely pythonic function, preserved by Numba\n",
    "# It can be accessed by .py_func()\n",
    "simple_sum.py_func(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9b61c-67f4-4a2c-aa31-dac77e042924",
   "metadata": {},
   "source": [
    "One important aspect to be aware of is that the JIT compilation occurs during the **first** function call. This results in:\n",
    "- Higher execution time for the first run\n",
    "- Significantly faster subsequent executions\n",
    "- One-time compilation cost that amortizes over multiple calls\n",
    "\n",
    "This behavior is particularly important to consider when:\n",
    "1. Benchmarking code performance\n",
    "2. Working with time-critical applications\n",
    "3. Running short scripts that only execute the function once\n",
    "\n",
    "> For accurate performance measurements, always discard the first function call, as it includes the compilation overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464cf30-4ce0-4961-9561-66a697e4692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure execution time across multiple runs\n",
    "N_TRIES = 20\n",
    "measurements = np.zeros(N_TRIES)\n",
    "\n",
    "# Run the function N_TRIES times and measure each execution\n",
    "for i in range(N_TRIES):\n",
    "   start = time.perf_counter()\n",
    "   simple_sum(input_data)\n",
    "   stop = time.perf_counter()\n",
    "   measurements[i] = stop - start\n",
    "\n",
    "# Convert to microseconds for better readability\n",
    "measurements = measurements * 1e6\n",
    "\n",
    "# Print statistics including first run (with compilation)\n",
    "print(\"All iterations (including compilation overhead):\")\n",
    "print(f\"Average: {np.mean(measurements):.2f} µs\")\n",
    "print(f\"Minimum: {np.min(measurements):.2f} µs\")\n",
    "print(f\"Maximum: {np.max(measurements):.2f} µs\")\n",
    "\n",
    "print(\"\\nExcluding first iteration (pure execution time):\")\n",
    "print(f\"Average: {np.mean(measurements[1:]):.2f} µs\")\n",
    "print(f\"Minimum: {np.min(measurements[1:]):.2f} µs\")\n",
    "print(f\"Maximum: {np.max(measurements[1:]):.2f} µs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212a150-d360-41ca-99fe-88ac50f713c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 -r 5\n",
    "\n",
    "# Measure jitted function performance using IPython's timeit magic\n",
    "simple_sum(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7772792-c686-4481-af3c-8197125de6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 -r 5\n",
    "\n",
    "# Compare against NumPy's optimized sum function\n",
    "np.sum(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feef125-0052-49dd-a806-55861eef0f39",
   "metadata": {},
   "source": [
    "This simple benchmark reveal significant performance differences:\n",
    "\n",
    "1. **NumPy's sum function**:\n",
    "  - Hundreds of times faster than pure Python\n",
    "  - Demonstrates the power of vectorized operations\n",
    "  - Optimized `C` implementation under the hood\n",
    "\n",
    "2. **Numba JIT-compiled function**:\n",
    "  - 50-100x speedup compared to pure Python\n",
    "  - Achieves performance comparable to NumPy for this simple task\n",
    "  - Maintains readable Python syntax while delivering near-`C` speed\n",
    "\n",
    "This comparison highlights two key strategies for high-performance Python code:\n",
    "- Using vectorized operations (NumPy approach)\n",
    "- JIT compilation of pure Python code (Numba approach)\n",
    "\n",
    "The advantage of Numba is that it allows you to write clear, straightforward Python code while still achieving performance similar to optimized `C`-level implementations like NumPy's.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d017f24-a892-43ab-b455-6f228d22c404",
   "metadata": {},
   "source": [
    "### Types\n",
    "\n",
    "One of the key advantages Numba offers over plain Python is its ability to infer data types and JIT-compile functions for the specific types being used. This results in more efficient code execution.\n",
    "\n",
    "For example, consider the `simple_sum` function we have applied so far to a NumPy array of floats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc021601-d883-4fc6-a8e6-f1213a5fe6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the first element in the input_data array\n",
    "type(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcca2d-e443-4d2d-bb41-309a80a38641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the types inferred and used by Numba for the simple_sum function\n",
    "simple_sum.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d536ef10-1a45-4c0f-ac76-d25b9a5fd7c8",
   "metadata": {},
   "source": [
    "If we use the function with a different input type, Numba will recompile the function to match the new type. \n",
    "\n",
    "This ensures optimal performance for various data types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18cf7b-85e6-4f49-9938-0c058b4a831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an array of random integers scaled by 10\n",
    "input_data_int = 10 * np.random.randint(low=0, high=100, size=100_000)\n",
    "\n",
    "# Check the type of the first element in the new input_data array\n",
    "type(input_data_int[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e794f1c-6dc7-46eb-abbb-9514d3549222",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 -r 5\n",
    "\n",
    "# Measure the jitted function over the new integer data array\n",
    "simple_sum(input_data_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0852c-377c-48b2-b59f-f175b63e1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect once again the types inferred and used by Numba\n",
    "simple_sum.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd735a0a-edf9-432e-ad22-45a74f2ece33",
   "metadata": {},
   "source": [
    "We observe similar speedups with other functions that use `for` loops.\n",
    "\n",
    "For instance, consider the cumulative sum function, which takes an array as input and returns an array as output, rather than a single scalar.\n",
    "\n",
    "Here, we further take advantage of Numba's ability to efficiently interpret and handle the data types of both input and output arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7b37e8c-dc67-4b8e-bea6-9566b6745fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cumulative sum of all elements in an array using Numba\n",
    "@jit\n",
    "def simple_cumsum(data):\n",
    "    # Initialize the output array with the same shape as the input\n",
    "    out = np.zeros_like(data)\n",
    "    \n",
    "    # Variable to store the running sum\n",
    "    s = 0\n",
    "    \n",
    "    # Loop through the input array to compute the cumulative sum\n",
    "    for n in range(len(data)):\n",
    "        s += data[n]\n",
    "        out[n] = s\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f35e9-e177-4a9f-9d72-a87196d4e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 -r 5\n",
    "\n",
    "# Measure the purely pythonic function\n",
    "simple_cumsum.py_func(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e15b2b-3d87-41d4-b8dd-56249cb87ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 -r 5\n",
    "\n",
    "# Measure the jitted function\n",
    "simple_cumsum(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d213916-bcb5-471c-a70b-5626a4a59a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 -r 5\n",
    "\n",
    "# Measure the NumPy's optimized function\n",
    "np.cumsum(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0109d5-5393-464f-b64a-52727def2f3d",
   "metadata": {},
   "source": [
    "In this case the jit version of the cumulative sum function out-performs the NumPy `cumsum` function by a factor ~two. \n",
    "\n",
    "The NumPy function `cumsum` is more versatile than the JIT function, so the comparison is not entirely fair, but it is remarkable that we can reach performance that is comparable to compiled code by JIT compiling Python code with a single function decorator. \n",
    "\n",
    "This allows us to use loop-based computations in Python without performance degradation, which is particularly useful for algorithms that are not easily written in vectorized form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25f18f-f128-42d9-b8bf-f96d0ffcaeea",
   "metadata": {},
   "source": [
    "### `nopython` Mode - A More Complex Example\n",
    "\n",
    "Let's explore a more complex example: evaluating a ***Julia fractal***. \n",
    "\n",
    "This requires a variable number of iterations for each point in a matrix of coordinates in the complex plane. A point $z$ in the complex plane belongs to the Julia set if, after repeatedly applying the iteration formula $z \\leftarrow z^2 + c$, it does not diverge after a large number of iterations.\n",
    "\n",
    "To generate a Julia fractal graph, we loop over a grid of coordinate points, apply the iteration $z \\leftarrow z^2 + c$, and store the number of iterations required for the value to diverge beyond a given bound (in this case, an absolute value larger than $2.0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cf510bb-0393-414b-b837-5db29a818e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `nopython` JIT mode\n",
    "# Equivalent to `@jit(nopython=True)`\n",
    "@njit\n",
    "def julia_fractal(z_re, z_im, j):\n",
    "    # Loop over the real and imaginary components of the grid\n",
    "    for m in range(len(z_re)):\n",
    "        for n in range(len(z_im)):\n",
    "            # Initialize the complex number z with real and imaginary parts\n",
    "            z = z_re[m] + 1j * z_im[n]\n",
    "            \n",
    "            # Perform up to 256 iterations to check divergence\n",
    "            for t in range(256):\n",
    "                z = z ** 2 - 0.05 + 0.68j  # Update z using the Julia set formula\n",
    "                if np.abs(z) > 2.0:  # Check for divergence\n",
    "                    j[m, n] = t  # Store the number of iterations before divergence\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7aba2c-a199-475f-9b0e-4e075255b0b5",
   "metadata": {},
   "source": [
    "This implementation is simple and straightforward due to the use of explicit loops, but in pure Python, these three nested loops would be prohibitively slow.\n",
    "\n",
    "However, by leveraging JIT compilation with Numba, we can achieve a significant speed-up.\n",
    "\n",
    "By default, Numba gracefully falls back on the standard Python interpreter when it fails to generate optimized code. An exception to this occurs when the `nopython=True` argument is used with `numba.jit`. In this case, the JIT compilation will fail if Numba cannot generate fully statically typed code. You can achieve the same effect by explicitly using the `@njit` decorator instead of `@jit`.\n",
    "\n",
    "When automatic type inference fails, the resulting JIT-compiled code usually offers little to no speed-up. Therefore, it's often advisable to use `nopython=True` (or `@njit`) to ensure that we detect failures early when Numba is unlikely to produce optimized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4837860-5ffa-4e57-a3ac-f8c46e5af913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up grid size and initialize the output array for iterations\n",
    "N = 1024 // 2\n",
    "j = np.zeros((N, N), np.int64)\n",
    "\n",
    "# Create linearly spaced values for the real and imaginary components of the grid\n",
    "z_real = np.linspace(-1.5, 1.5, N)\n",
    "z_imag = np.linspace(-1.5, 1.5, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d0ef58-e9dc-4779-b3f7-7e5a55d233c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1 # Only 1 iteration here please!\n",
    "\n",
    "# Measure the purely pythonic function\n",
    "julia_fractal.py_func(z_real, z_imag, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "081e0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize the grid\n",
    "j = np.zeros((N, N), np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631d58c-251c-4263-a257-f934a373bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 5 -r 5\n",
    "\n",
    "# Measure the jitted function\n",
    "julia_fractal(z_real, z_imag, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e202d500-21bc-4d26-945b-3ee556b3a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Julia fractal result\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(j, cmap=plt.cm.RdBu_r, extent=[-1.5, 1.5, -1.5, 1.5])\n",
    "ax.set_xlabel(\"$\\mathrm{Re}(z)$\", fontsize=18)\n",
    "ax.set_ylabel(\"$\\mathrm{Im}(z)$\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd3d14-81b7-4d87-8548-b43a0bd6edb1",
   "metadata": {},
   "source": [
    "This speedup is quite remarkable! It's also interesting to note that a fairly-optimized NumPy implementation does not outperform the loop-heavy Numba version. \n",
    "\n",
    "This demonstrates the power of JIT compilation in handling complex, loop-based algorithms efficiently, where traditional array-based operations might not always be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f22bf447-7e8a-4d65-8cf7-d6c523ae324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy based Julia set evaluation\n",
    "def julia_fractal_np(z_re, z_im, j):\n",
    "    # Create a meshgrid of complex numbers from the real and imaginary components\n",
    "    Z_re, Z_im = np.meshgrid(z_re, z_im)\n",
    "    Z = Z_re + 1j * Z_im\n",
    "    \n",
    "    # Define the constant for the Julia set formula\n",
    "    C = -0.05 + 0.68j\n",
    "    \n",
    "    # Initialize a mask to track points that haven't diverged yet\n",
    "    mask = np.ones(Z.shape, dtype=bool)\n",
    "\n",
    "    # Iterate up to 256 times to check for divergence\n",
    "    for t in range(256):\n",
    "        Z[mask] = Z[mask] ** 2 + C  # Update Z only for points that haven't diverged\n",
    "        mask = np.abs(Z) <= 2.0  # Update the mask to track non-diverged points\n",
    "        j[mask] = t  # Store the number of iterations before divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed654456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize the grid\n",
    "j = np.zeros((N, N), np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc14186-2dee-47f6-8809-d3826a2301f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "\n",
    "# Measure the NumPy-based implementtion\n",
    "julia_fractal_np(z_real, z_imag, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0463a8b-bdc0-4b37-a8e1-ac9974bf0b30",
   "metadata": {},
   "source": [
    "### Lazy vs. Eager Compilation\n",
    "\n",
    "The standard usage of the `@jit/@njit` decorator results in _lazy_ compilation.\n",
    "\n",
    "_Lazy_ compilation means that the function will be compiled only when it is first called. At that point, Numba will infer the argument types based on the actual inputs and generate optimized code accordingly.\n",
    "\n",
    "To perform _eager_ compilation, we need to explicitly tell Numba the function signature in advance, specifying the expected types.\n",
    "\n",
    "Returning to the `simple_sum` function, if we expect it to work on a specific data type, we can inform the compiler ahead of time and allow it to perform type-specific compilation.\n",
    "\n",
    "For example, if we want the function to handle single-precision floats, we can specify this using `float32` or its shorthand `f4`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4132959-da66-4789-8642-91775fbaeafe",
   "metadata": {},
   "source": [
    "Type name(s) |           Shorthand|        Comments|\n",
    "---|---|---|\n",
    "`boolean`                 |`b1`              |represented as a byte|\n",
    "`uint8`, `byte`             |`u1`              |8-bit unsigned byte|\n",
    "`uint16`                  |`u2`              |16-bit unsigned integer|\n",
    "`uint32`                  |`u4`              |32-bit unsigned integer|\n",
    "`uint64`                  |`u8`              |64-bit unsigned integer|\n",
    "`int8`, `char`              |`i1`              |8-bit signed byte|\n",
    "`int16`                   |`i2`              |16-bit signed integer|\n",
    "`int32`                   |`i4`              |32-bit signed integer|\n",
    "`int64`                   |`i8`              |64-bit signed integer|\n",
    "`float32`                 |`f4`              |single-precision floating-point number|\n",
    "`float64`, `double`         |`f8`              |double-precision floating-point number|\n",
    "`complex64`               |`c8`              |single-precision complex number|\n",
    "`complex128`              |`c16`              |double-precision complex number|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cab69d",
   "metadata": {},
   "source": [
    "When declaring a function for eager JIT compilation, both the type and the structure of the input and output data must be specified:\n",
    "\n",
    "- `type` represents a scalar.\n",
    "- `type[:]` represents a vector (or 1D array).\n",
    "\n",
    "For example, the signature `int32(int32[:])` denotes a function that takes a vector of integers as input and returns a scalar integer as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f16c56ab-e6fa-407d-969c-3926905f74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import f4\n",
    "\n",
    "# Function returning a float32 and taking an array of float32 as input\n",
    "# This is an alternative to --> @njit(\"float32(float32[:])\")\n",
    "@njit(\"f4(f4[:])\")\n",
    "def simple_sum_float32(data):\n",
    "    s = 0  # Initialize sum\n",
    "    for d in data:\n",
    "        s += d  # Accumulate sum\n",
    "    return s  # Return the result as a float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514b030-8de4-424b-bd42-a79740209596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an array of random floats scaled by 10 and converted to float32\n",
    "input_data_f32 = 10. * np.random.random(100_000).astype('float32')\n",
    "\n",
    "# Check the data type of the first element in the input_data_f32 array\n",
    "input_data_f32[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03863e81-c09e-4c83-9d23-4922ecef23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 20 -r 5\n",
    "\n",
    "# Measure the jitted function\n",
    "simple_sum_float32(input_data_f32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767332ce-6ea1-49aa-8fd5-a641d832896a",
   "metadata": {},
   "source": [
    "### Other Interesting Compiling Options and Usages\n",
    "\n",
    "In addition to the main Numba compiling options, we also have:\n",
    "\n",
    "- **`nopython`**: \n",
    "\n",
    "This option forces Numba to compile to machine code without relying on the Python `C` API. This results in higher performance code, but it requires that the types of all inputs and outputs can be inferred. If Numba cannot infer the types (for example, if you use a specific Python data type that cannot be resolved at compile time), `@jit` will fall back to the so-called `object mode`, which results in significantly slower performance. Note that `@njit` is simply an alias for `@jit(nopython=True)`.\n",
    "\n",
    "- **`cache`**: \n",
    "\n",
    "This option instructs Numba to save the results of function compilation into a **file-based cache**. When you use a function that has been previously compiled with Numba, it retrieves the compiled version from the cache instead of recompiling. This is especially useful in larger projects where multiple files or notebooks are involved.\n",
    "\n",
    "- **`parallel`**: \n",
    "\n",
    "This option enables Numba to compile a version of the function that will run in parallel across multiple native threads (without the Global Interpreter Lock!). Numba supports _explicit parallel loop declaration_, allowing for embarrassingly parallel computation across loop iterations. You can specify this using `numba.prange` instead of `range` in your `for` loops. \n",
    "\n",
    "However, be cautious: using parallel execution does not guarantee a speedup, as it involves threading and may incur overhead from scheduling tasks across processing units. If the input data is small enough, the scheduling overhead might negate any performance gains from threading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b03c1d-5d41-4cef-82ee-063c6d6ae827",
   "metadata": {},
   "source": [
    "### Example - Gravitational Interaction\n",
    "\n",
    "Given $N = 1000$ masses scattered in 3D space, we will compute the gravitational force exerted on each mass. \n",
    "\n",
    "In this example, we will create a function to calculate the gravitational force on each mass based on its interactions with all other masses in the 3D space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0607cbda-6e20-4424-8d6d-028efed9cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import prange\n",
    "\n",
    "# Gravitational constant\n",
    "G = 6.67430e-11 \n",
    "\n",
    "# Force Numba to parallelize - remember to use `prange` for the parallel loop\n",
    "@njit(parallel=True)\n",
    "def compute_gravitational_forces(masses, positions):\n",
    "    # Number of particles\n",
    "    n = masses.shape[0]\n",
    "    \n",
    "    # Initialize forces in 3D space (x, y, z)\n",
    "    forces = np.zeros((n, 3))  \n",
    "\n",
    "    # Loop over each pair of particles\n",
    "    for i in prange(n):\n",
    "        for j in prange(n):\n",
    "            if i != j:  # Ensure we don't compute force on itself\n",
    "                r_vec = positions[j] - positions[i]  # Vector from i to j\n",
    "                r_mag = np.sqrt(np.sum(r_vec ** 2))  # Magnitude of the distance vector\n",
    "                \n",
    "                # Calculate the magnitude of the gravitational force\n",
    "                force_mag = G * masses[i] * masses[j] / r_mag ** 2\n",
    "                \n",
    "                # Update the force vector for particle i in the direction of j\n",
    "                forces[i] += force_mag * r_vec / r_mag  \n",
    "\n",
    "    return forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a92c411d-151b-4f94-88f2-ae4ccaf8ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of particles\n",
    "n_particles = 1_000\n",
    "\n",
    "# Generate random masses between 1e16 and 1e32\n",
    "masses = np.random.uniform(1e16, 1e32, n_particles)\n",
    "\n",
    "# Generate random positions in 3D space between -1e11 and 1e11\n",
    "positions = np.random.uniform(-1e11, 1e11, (n_particles, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16044759-8b96-4c5f-a836-0867b5588e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the particles in 3D\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot particles with size proportional to their masses\n",
    "ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], \n",
    "           color='blue', s=100 * masses / max(masses))  # Scale marker size by mass\n",
    "\n",
    "# Set labels for the axes\n",
    "ax.set_xlabel('X Position (m)')\n",
    "ax.set_ylabel('Y Position (m)')\n",
    "ax.set_zlabel('Z Position (m)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b6d21-dc3b-4b4e-9c14-4ecf480caa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Measure the jitted function\n",
    "forces = compute_gravitational_forces(masses, positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97764bf1-a7b3-4df8-9cc2-829e940cd329",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# If you have time... measure the time of the non-jitted function\n",
    "# forces = compute_gravitational_forces.py_func(masses, positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c4d36-3ce7-472b-8a63-160fd6784543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "# Plotting the particles and their corresponding gravitational force vectors\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot particles with size proportional to their masses\n",
    "ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], \n",
    "           color='blue', s=200 * masses / max(masses))\n",
    "\n",
    "# Compute force norms for color mapping\n",
    "force_norms = np.linalg.norm(forces, axis=1)\n",
    "normed_forces = (force_norms - force_norms.min()) / (force_norms.max() - force_norms.min())\n",
    "cmap = cm.get_cmap('hot')\n",
    "\n",
    "# Plot force vectors for each particle\n",
    "for i in range(n_particles):\n",
    "    ax.quiver(\n",
    "        positions[i, 0], positions[i, 1], positions[i, 2], \n",
    "        forces[i, 0], forces[i, 1], forces[i, 2], \n",
    "        color=cmap(normed_forces[i]),  # Color based on the normalized force magnitude\n",
    "        length=2e10,  # Scale length of vectors for better visualization\n",
    "        normalize=True  # Normalize vectors for consistent representation\n",
    "    )\n",
    "\n",
    "# Set labels for the axes\n",
    "ax.set_xlabel('X Position (m)')\n",
    "ax.set_ylabel('Y Position (m)')\n",
    "ax.set_zlabel('Z Position (m)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78ba3d-cb97-43fe-b8b3-8a417b3f4bca",
   "metadata": {},
   "source": [
    "## @vectorize\n",
    "\n",
    "### The Basics\n",
    "\n",
    "In NumPy, universal functions, or `ufunc`s, are functions that operate on ndarrays in an element-wise fashion. Examples include the addition of two ndarrays or the multiplication of an ndarray with a scalar.\n",
    "\n",
    "Under the hood, NumPy implements these `ufunc`s in pure `C`, allowing them to efficiently process each element of the ndarray, potentially in a vectorized manner.\n",
    "\n",
    "Writing a custom `ufunc` in NumPy can be quite complex, as it requires a deeper understanding of the underlying implementation than what typical users are accustomed to.\n",
    "\n",
    "Numba simplifies this process by allowing you to create \"vector\" versions of Python functions that operate on all scalar elements of a NumPy array with the same speed as `ufunc`s.\n",
    "\n",
    "Using the `@vectorize` decorator, Numba can compile a pure Python function into a `ufunc` that operates over NumPy arrays as efficiently as traditional `ufunc`s written in C. The `@vectorize` decorator is especially useful for creating ufuncs that are not merely combinations of existing NumPy operations.\n",
    "\n",
    "The same considerations regarding _lazy_ vs _eager_ compilation apply in this context as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c60553-4c1b-4d3e-8857-94e7d00460a9",
   "metadata": {},
   "source": [
    "Let's start by vectorizing a trivial `simple_add` function using Numba's `@vectorize` decorator. We will eagerly compile it to handle both integers (32 and 64 bits) and floats (32 and 64 bits).\n",
    "\n",
    "The following implementation will demonstrate how to define a function that adds two numbers and can be applied element-wise to NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee6abf95-2171-46e6-a3e4-5444f2717584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize, int32, int64, float32, float64\n",
    "\n",
    "# Vectorize the addition of two values\n",
    "# Specialize this function to add either integers (32 and 64 bits)\n",
    "# or floats (single or double precision)\n",
    "@vectorize(['int32(int32, int32)',\n",
    "            'int64(int64, int64)',\n",
    "            'float32(float32, float32)',\n",
    "            'float64(float64, float64)'])\n",
    "def simple_add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc14b4ce-329a-439e-8915-f861fd66efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two random arrays of floats\n",
    "a = 10 * np.random.random(100_000)\n",
    "b = 20 * np.random.random(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d851317-7142-42b4-a940-2e40d5364e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the vectorized simple_add function to add arrays a and b\n",
    "c = simple_add(a, b)\n",
    "\n",
    "# Display the result\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde57cb5-e60d-4905-ab66-60eb9f944d35",
   "metadata": {},
   "source": [
    "#### Differences Between `@vectorize` and `@jit`\n",
    "\n",
    "One common question is whether there is any difference between using `@vectorize` and writing a `@jit` function that operates on all elements of the ndarrays.\n",
    "\n",
    "There is a very interesting and important distinction that arises when using `@vectorize`: all NumPy `ufunc`s automatically support additional features such as **reduction**, **accumulation**, and **broadcasting**.\n",
    "\n",
    "Using the example above, let's explore how these features enhance the functionality of the `@vectorize` approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde49115-be5b-4c54-9225-ea0184cfa095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using broadcasting: Adding a scalar to the array b\n",
    "a_1 = 1  # Scalar value\n",
    "c = simple_add(a_1, b)  # The scalar a_1 will be broadcasted to each element of b\n",
    "\n",
    "# Display the result\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250351a3-e75d-4337-9a69-01f685be2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using broadcasting with reshaped arrays\n",
    "a_2 = a.reshape(100, 1_000)  # Reshape array a into a 2D array of shape (100, 1,000)\n",
    "b_2 = b.reshape(100, 1_000)  # Reshape array b into a 2D array of shape (100, 1,000)\n",
    "\n",
    "# Perform element-wise addition using the vectorized simple_add function\n",
    "c = simple_add(a_2, b_2)\n",
    "\n",
    "# Display the result\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0c9cc-4e33-4459-91fe-e201cb70feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing reduction using the simple_add function\n",
    "# This sums the elements of array a along the specified axis (0 in this case)\n",
    "result_reduction = simple_add.reduce(a, axis=0)\n",
    "\n",
    "# Display the result of the reduction\n",
    "result_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559cefc2-2ad5-4936-a0a5-eb3c944667c6",
   "metadata": {},
   "source": [
    "The `vectorize` decorator in Numba supports multiple targets for executing the vectorized function:\n",
    "\n",
    "- **`cpu`**: Runs the vectorized function in a single-threaded manner on the CPU.\n",
    "\n",
    "- **`parallel`**: Executes the vectorized function in a multi-threaded manner across all available CPUs (without the Global Interpreter Lock, or GIL). It is important to note that this approach involves threading, which can introduce a small overhead due to the scheduling of tasks across multiple threads. This option is beneficial when the dataset is large enough to \"hide\" the latency associated with the initial scheduling.\n",
    "\n",
    "- **`cuda`**: Enables the vectorized function to run on a GPU as a dedicated CUDA kernel, allowing for significant performance improvements in suitable scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497464c-73e1-4123-8c5c-8451a15eadf5",
   "metadata": {},
   "source": [
    "### Example - Invert Image\n",
    "\n",
    "Given an RGB image, invert its colors using Numba's `@vectorize` decorator. \n",
    "The idea is to create a function that takes an RGB image as input and returns a new image with inverted colors. This is achieved by subtracting each color channel's values from the maximum value, which is typically 255 for an 8-bit image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74f0f9b1-3c86-4460-8ec8-6611264c41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a vectorized function to invert the colors of an image\n",
    "@vectorize(['uint8(uint8)'], target='parallel')\n",
    "def invert_color(pixel):\n",
    "    return 255 - pixel  # Invert the color by subtracting from 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40626ae5-be0b-4e48-9c1a-84cd16d43711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a sample image using Matplotlib\n",
    "image = plt.imread('sample_image.png')  # Read the image file\n",
    "image.shape  # Display the shape of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38427ea1-4e66-4cc6-9f96-f7acaa31052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type of the image array\n",
    "image.dtype  # This will show the data type of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "523d9c57-f5f2-4dec-8d8e-81817e6cda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to uint8 format (values between 0 and 255)\n",
    "if image.dtype != np.uint8:\n",
    "    image = (image * 255).astype(np.uint8)  # Scale and convert to uint8 if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389718c-b6f4-49f2-a0f0-9323606306d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the vectorized function to invert the colors of the image\n",
    "inverted_image = invert_color(image)  # This will run the color inversion in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e2e3f-c89c-409f-b21b-0cef11db7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original and inverted images side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(image)  # Display the original image\n",
    "ax[0].set_title('Original Image')  \n",
    "ax[0].axis('off')  \n",
    "\n",
    "ax[1].imshow(inverted_image)  # Display the inverted image\n",
    "ax[1].set_title('Inverted Image')  \n",
    "ax[1].axis('off')  \n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5199e-9eff-4f0b-8131-fcebca8a0a83",
   "metadata": {},
   "source": [
    "### Extending it to `@guvectorize`\n",
    "\n",
    "The `@vectorize` decorator enables the definition and compilation of element-wise functions for faster execution. To work with ndarrays more flexibly, Numba offers the `@guvectorize` decorator, which allows you to write universal functions (ufuncs) that can operate on an arbitrary number of elements of input arrays and return arrays of potentially differing dimensions.\n",
    "\n",
    "One key point to note about `@guvectorize` functions is that, unlike `@vectorize` functions, `guvectorize` functions do not return their result values. Instead, they function similarly to \"void\" functions: they take the result/output values as input parameters and fill them. This behavior is akin to kernels in CUDA.\n",
    "\n",
    "This design choice is because the array is allocated by NumPy’s dispatch mechanism, which calls into the Numba-generated code to perform the operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea499c-8bc1-4774-8657-0e445b0fb967",
   "metadata": {},
   "source": [
    "One very simple example, useful to understand the logic of this, can be the sum of a scalar value to all elements of an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27a14179-f731-430b-a938-a081d6ebe290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a guvectorized function to add a scalar to each element of an input array\n",
    "@guvectorize([(int64[:], int64, int64[:])], '(n),()->(n)', target='parallel')\n",
    "def gu_vector_add(x, y, res):\n",
    "    for i in range(x.shape[0]):\n",
    "        res[i] = x[i] + y  # Add the scalar y to each element of array x\n",
    "    pass  # Do not return res; the output is filled in the provided res array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a25cbbb-8599-43c4-bd52-20cebb78cddc",
   "metadata": {},
   "source": [
    "The declaration of the input and output layouts is usually reported in symbolic form: `(n),()->(n)`. \n",
    "\n",
    "- `()` represents a scalar (in this case, of type `int64`)\n",
    "- `(n)`, `(m)`, etc. represent 1D arrays (e.g., `int64[:]`)\n",
    "- `(n,n)`, `(n,m)`, etc. represent 2D arrays (e.g., `int64[::]`)\n",
    "- ...\n",
    "\n",
    "The previous definition instructs NumPy that the function takes a one-dimensional array of n elements `(n)`, a scalar `()`, and returns a one-dimensional array of the same number of elements as the input array `(n)`.\n",
    "\n",
    "As always in Numba, you can pass a list of supported concrete signatures to specify for which types Numba should compile the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "acdefc6b-16c7-4744-b538-a733af2c14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a scalar value\n",
    "sca = 10\n",
    "\n",
    "# Create a random integer array with values between 0 and 100, of size 100,000\n",
    "arr = np.random.randint(low=0, high=100, size=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb151701-9b7c-4ffe-b392-37f00d87ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Apply the guvectorized function to add the scalar to the array\n",
    "result = gu_vector_add(arr, sca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f86675-a76a-4565-a129-db252312e032",
   "metadata": {},
   "source": [
    "### Example - 1D Denoising\n",
    "\n",
    "It is given a 1D signal composed of a single frequency and some additional Gaussian noise. \n",
    "\n",
    "We will apply a moving average filter to denoise the signal. \n",
    "\n",
    "The moving average filter will help smooth out the noise by averaging the values within a specified window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81b233-5acf-479c-9b20-12c2f407c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a realistic noisy signal (sine wave with added noise)\n",
    "np.random.seed(123)  # For reproducibility\n",
    "t = np.linspace(0, 4 * np.pi, 500)  # Time values\n",
    "signal = np.sin(t) # Sine wave\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "# Plot the original signal\n",
    "plt.plot(t, signal, color='green', label='Original Signal')\n",
    "plt.title('Original Signal')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2837f-fc96-496c-8a39-4e0a8284c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some Gaussian noise\n",
    "noise = np.random.normal(scale=0.5, size=t.shape)\n",
    "noisy_signal = signal + noise\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "# Plot the noisy signal\n",
    "plt.plot(t, signal, color='green', label='Original Signal')\n",
    "plt.plot(t, noisy_signal, color='grey', label='Noisy Signal')\n",
    "plt.title('Noisy Signal')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82edf3-1f23-42ab-9d38-2f021de01c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple moving average kernel\n",
    "kernel_size = 20\n",
    "kernel = np.ones(kernel_size) / kernel_size  # Average kernel --> [1/20, 1/20, 1/20, ...]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "# Plot the noisy signal and an instance of a kernel function overimposed\n",
    "plt.plot(t, signal, color='green', label='Original Signal')\n",
    "plt.plot(t, noisy_signal, color='grey', label='Noisy Signal')\n",
    "plt.plot(t[:kernel_size], kernel, color='red', label='Kernel')\n",
    "plt.title('Kernel')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f365e4b8-ba22-45d8-a657-218d6d4475a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the convolution function using guvectorize\n",
    "@guvectorize([(float64[:], float64[:], float64[:])], '(n),(k)->(n)', target='parallel')\n",
    "def convolve_1d(signal, kernel, result):\n",
    "    n = signal.shape[0]  # Length of the input signal\n",
    "    k = kernel.shape[0]  # Length of the convolution kernel\n",
    "    half_k = k // 2  # Half the kernel size for centering\n",
    "\n",
    "    for i in range(n):\n",
    "        tmp = 0.0  # Temporary variable to hold the convolution result\n",
    "        for j in range(k):\n",
    "            # Check bounds to prevent index errors\n",
    "            if 0 <= i - half_k + j < n:\n",
    "                tmp += signal[i - half_k + j] * kernel[j]  # Perform the convolution\n",
    "        result[i] = tmp  # Store the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9197a69f-8aac-4a85-a90b-222c99378f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output array to hold the convolution result\n",
    "smoothed_signal = np.empty_like(noisy_signal)\n",
    "\n",
    "# Perform the convolution\n",
    "convolve_1d(noisy_signal, kernel, smoothed_signal)\n",
    "\n",
    "# Plot the final result\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "plt.plot(t, signal, color='green', label='Original Signal')\n",
    "plt.plot(t, noisy_signal, color='grey', label='Noisy Signal')\n",
    "plt.plot(t, smoothed_signal, color='blue', label='Smoothed Signal')\n",
    "plt.title('Smoothed Signal with Moving Average')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
